---
title: "Music Popularity Prediction Model -- Final Report"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Olivia Harbison"
date: today

format:
  html:
    toc: true
    embed-resources: true
    
execute:
  echo: false
  warning: false

from: markdown+emoji 
reference-location: margin
citation-location: margin
---



```{r packages}
#| echo: false
library(tidyverse)
library(tidymodels)
library(here)

tidymodels_prefer()
set.seed(80)

# note: all data will be loaded throughout the document / as needed
```

## Introduction
The music industry is a fickle beast. Everyone wants to have the next hit and be the next Taylor Swift, but how do we make a star? If we could predict what makes songs or albums popular, we could become the next big thing. This is one of many reasons I chose to explore music popularity for my project. 

Although I personally have no interest in becoming a pop star, I love listening to music and I've always been curious as to what makes some songs popular and others not. To dig into this, I found a dataset that contains information scraped from Spotify about individual songs and their popularity^[This dataset can be found [here](https://www.kaggle.com/datasets/elemento/music-albums-popularity-prediction?select=train.csv) on kaggle.]. I will use this data to create a model that predicts how popular music albums are on a scale of 1 to 100. 


## Data Overview
The full dataset used here is 160,000 albums from 1917 to 2021, with the marjority having been released in the last 40 years. For computational efficiency, I'm going to use only albums released between 1980 and 2010. Furthermore, I removed all albums containing fewer than three songs, because I feel they should not be classified as albums. Once these changes were made, the dataset was left with 19,184 observations. 

The slimmed down dataset had 39 variables, of which 32 were numerical, 6 were categorical, and 1 was the release date. There was no missingness present, but there were some imbalanced variables that were dealt with in the advanced recipe below. An exploratory data analysis was conducted to explore variable imbalance and relationships between variables. More information can be found below in the appendix. 

The target variable in this set of regression models is the popularity of the album. This was scored on a scale of 1 to 100, with 100 being very popular and 1 being not popular. The variable did not need to be transformed. Furthermore, possible relationships between the target variable and predictor variables were explored but no clear relationships were found. There was a slight relationship between popularity and energy level, but not major enough to make any adjustments.


## Methods
Should cover the data splitting procedure and clearly identify what type of prediction problem it is. State and describe the model types you will be fitting. Describe any parameters that will be tuned. Describe what recipes will be used. Describe the resampling technique used. In some cases an extended discussion about recipe variations might be useful. Especially if students are using recipe variation to try and explore the predictive importance of certain variables. Explain the metric that will be used to compare and ultimately used to select a final model.

## Model Building & Selection Results
Should reiterate the metric that will be used to compare models and determine which will be the final/winning model. Include a table of the best performing model results. Review and analysis of tuning parameters should happen here. Should further tuning be explored? Or how should tuning be adjusted when fitting data like this in the future. This would be a good section to describe what the best parameters were for each model type. Could include a discussion comparing any systematic differences in performance between model types or recipes. If variations in recipes were used to explore predictive importance of certain variables, then it should be discussed here. The section will likely end with the selection of the final/winning model (provide your reasoning). Was it surprising or not surprising that this particular model won? Explain.

## Final Model Analysis
This is where you fit your final/winning model to the testing data. Assess the final model’s performance with at least the metric used to determine the winning model, but it is also advisable to use other performance metrics (especially ones that might be easier to communicate/understand). Should include an exploration of predictions vs the true values (graph) or a confusion matrix (table). Remember to consider the scale of your outcome variable at this time — did you transform the target variable? If a transformation was used, then you should consider conducting analyses on both the original and transformed scale of the target variable. Is the model any good? It might be the best of the models you tried, but does the effort of building a predictive model really pay off — is it that much better than a baseline/null model? Were there any features of the model you selected that make it the best (e.g. fits nonlinearity well)?

## Conclusion
State any conclusions or discoveries/insights. This is a great place for future work, new research questions, and next steps.

## References
Agarwal, M., & Elemento. (2022). Music Albums Popularity Prediction. Kaggle. [https://www.kaggle.com/datasets/elemento/music-albums-popularity-prediction](https://www.kaggle.com/datasets/elemento/music-albums-popularity-prediction)


### Appendix: technical info — if needed
A place to share complex and important technical steps that may highly impact explorations, but the details are too technical to share in main body of the report.

### Appendix: EDA — if needed
A place to place a more thorough EDA, if needed. This should not include any data from the testing dataset!

- put some of the skewed histograms in here
- put something demonstrating the relationships put into the interaction terms

### Appendix: extras — if needed
Add as many appendices as needed.







